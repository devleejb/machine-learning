{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Anomaly Detection\n",
    "\n",
    "Reference: https://www.kaggle.com/code/ysjang0926/kor-introduction-to-anomaly-detection-r01#Semi-Supervised-Classification-using-AutoEncoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- 필요한 라이브러리 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install kagglehub\n",
    "%pip install pandas\n",
    "%pip install numpy==1.26\n",
    "%pip install matplotlib\n",
    "%pip install scikit-learn\n",
    "%pip install seaborn\n",
    "%pip install --upgrade keras\n",
    "%pip install tensorflow\n",
    "%pip install setuptools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation\n",
    "\n",
    "- 필요한 데이터셋 다운로드\n",
    "- Pandas 데이터프레임 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "np.random.seed(203)\n",
    "\n",
    "data = pd.read_csv(f\"{path}/creditcard.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Time\"] = data[\"Time\"].apply(lambda x : x / 3600 % 24)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Time: 첫 번째 Transaction으로부터 경과된 시간(초)\n",
    "- V1 ~ V28: PCA 변환된 변수\n",
    "- Amount: 거래 금액\n",
    "- Class: Target 변수 (0: 정상, 1: 비정상)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = [\"#0101DF\", \"#DF0101\"]\n",
    "LABELS = [\"Non-Fraud\", \"Fraud\"]\n",
    "sns.countplot(x='Class', data=data, palette=colors)\n",
    "plt.title('Class Distribution \\n (0 : Non-Fraud / 1 : Fraud)', fontsize=13)\n",
    "plt.xticks(range(2), LABELS)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = data['Class'].value_counts().to_frame().reset_index()\n",
    "vc['percent'] = vc[\"Class\"].apply(lambda x : round(100*float(x) / len(data), 2))\n",
    "vc = vc.rename(columns = {\"index\" : \"Target\", \"Class\" : \"Count\"})\n",
    "vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 컬럼의 기초 통계값 확인\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null 값 체크: 결측치 갯수\n",
    "data.isnull().sum().max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null 값 체크: True/False\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사기 거래가 전체의 0.17%이어서 불균형이 크기 때문에, Non-fraud 거래 내역의 1,000행만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_fraud = data[data['Class'] == 0].sample(1000)\n",
    "fraud = data[data['Class'] == 1]\n",
    "\n",
    "df = pd.concat([non_fraud, fraud]).sample(frac=1).reset_index(drop=True)\n",
    "X = df.drop(['Class'], axis = 1).values\n",
    "Y = df[\"Class\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Fraud and Non-Fraud Transactions\n",
    "\n",
    "- 이상치가 있다는 것은 기존의 데이터가 어느 정도 패턴을 갖고있다는 것을 의미\n",
    "- `t-SNE`를 사용하여 Fraud와 Non-Fraud 거래의 특성을 시각화\n",
    "\n",
    "### t-SNE(t-Distributed Stochastic Neighbor Embedding)란?\n",
    "\n",
    "- 높은 차원의 복잡한 데이터를 2차원에 차원 축소하는 방법\n",
    "- 각 데이터 포인트 주변으로 유사도를 계산하여, 각 데이터 포인트를 2차원에서 원본 특성 공간에서 비슷한 데이터 구조는 가깝게 배치하고, 구조가 다른 데이터는 멀리 배치\n",
    "\n",
    "#### PCA와 차이점\n",
    "\n",
    "- PCA는 Linear한 방법을 사용하지만, t-SNE는 Non-linear한 방법을 사용\n",
    "- t-SNE는 Input Feature를 확인하기 어렵기 떄문에 t-SNE 결과만 가지고 무언가를 추론하기 어려움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def tsne_plot(x1, y1, name=\"graph.png\"):\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    X_t = tsne.fit_transform(x1)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(X_t[np.where(y1 == 0), 0], X_t[np.where(y1 == 0), 1], marker='o', color='g', alpha=0.8, label='Non Fraud')\n",
    "    plt.scatter(X_t[np.where(y1 == 1), 0], X_t[np.where(y1 == 1), 1], marker='o', color='r', alpha=0.8, label='Fraud')\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot(X, Y, \"original.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fraud 거래에 가까운 Non-Fraud 거래가 많기 때문에 정확하게 분류하기 어렵다는 것을 알 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoders to the Rescue\n",
    "\n",
    "### AutoEncoder란?\n",
    "\n",
    "- 출력이 입력과 동일한 특수한 유형의 Neural Network 아키텍처\n",
    "- 입력 데이터를 압축한(Encoder) 후 다시 복원하는(Decoder) 방법으로 학습\n",
    "- 고차원 상의 입력 데이터를 저차원 공간으로 Mapping하여 Latent Representation으로 표현하였다가, 다시 이렵과 같은 고차원의 공간으로 복원\n",
    "- 데이터가 잘 복원된 경우 저차원의 데이터 특성 공간을 잘 파악한 것임\n",
    "\n",
    "### 가정\n",
    "\n",
    "- 정상 관측치들은 불량 관측치보다 더 잘 복원될 것임\n",
    "- Reconstruct의 오차 이상치 점수를 산출하여, 특정 임계값보다 큰 경우 불량 관측치로 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras import regularizers\n",
    "\n",
    "## input layer \n",
    "input_layer = Input(shape=(X.shape[1],))\n",
    "\n",
    "## encoding part\n",
    "encoded = Dense(100, activation='tanh', activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoded = Dense(50, activation='relu')(encoded)\n",
    "\n",
    "## decoding part\n",
    "decoded = Dense(50, activation='tanh')(encoded)\n",
    "decoded = Dense(100, activation='tanh')(decoded)\n",
    "\n",
    "## output layer\n",
    "output_layer = Dense(X.shape[1], activation='relu')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "\n",
    "autoencoder = Model(input_layer, output_layer)\n",
    "autoencoder.compile(optimizer=\"adadelta\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 변수의 범위가 다르기 때문에 MinMaxScaler를 사용하여 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "x = data.drop([\"Class\"], axis=1)\n",
    "y = data[\"Class\"].values\n",
    "\n",
    "x_scale = preprocessing.MinMaxScaler().fit_transform(x.values)\n",
    "x_norm, x_fraud = x_scale[y == 0], x_scale[y == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(\n",
    "    x_norm[0:2000],\n",
    "    x_norm[0:2000],\n",
    "    batch_size=256,\n",
    "    epochs=10,\n",
    "    shuffle=True,\n",
    "    validation_split=0.20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "\n",
    "hidden_representation = Sequential()\n",
    "hidden_representation.add(autoencoder.layers[0])\n",
    "hidden_representation.add(autoencoder.layers[1])\n",
    "hidden_representation.add(autoencoder.layers[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_hid_rep = hidden_representation.predict(x_norm[:3000])\n",
    "fraud_hid_rep = hidden_representation.predict(x_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_x = np.append(norm_hid_rep, fraud_hid_rep, axis=0)\n",
    "y_n = np.zeros(norm_hid_rep.shape[0])\n",
    "y_f = np.ones(fraud_hid_rep.shape[0])\n",
    "rep_y = np.append(y_n, y_f)\n",
    "tsne_plot(rep_x, rep_y, \"latent_representation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fraud 거래와 Non-Frad 거래가 잘 구분되는 것을 확인할 수 있음\n",
    "- Linear하게 구분할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(rep_x, rep_y, test_size=0.25)\n",
    "clf = LogisticRegression(solver=\"lbfgs\").fit(train_x, train_y)\n",
    "pred_y = clf.predict(val_x)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(val_y, pred_y))\n",
    "\n",
    "print(\"\")\n",
    "print(\n",
    "    \"Logistic Regression Accuracy Score: \",\n",
    "    str(round(accuracy_score(val_y, pred_y) * 100, 3)) + \"%\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_pred=pred_y, y_true=val_y)\n",
    "cmp = ConfusionMatrixDisplay(cm)\n",
    "cmp.plot(cmap=plt.cm.Blues)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
